# )
# run the MSE
foreach(i = 1:nrow(runs)) %dopar% {
IATTCMSE::BET_MSE(
pdir,
HS,
HCR,
OM = runs[i, 5],
itrnum = runs[i, 3],
nquarters,
Mcycle,
n_extra_R,
startquarter,
endquarter,
EM_comp_fleet,
dat_name,
ctl_name,
ss_name,
clean = TRUE,
plot = FALSE,
MSY = FALSE
)
}
i = 25; OM = runs[i, 5]; itrnum = runs[i, 3];
clean = TRUE; plot = FALSE; MSY = FALSE
IATTCMSE::BET_MSE(pdir,sdir,HS,HCR = HCR,OM = runs[i, 5],itrnum = runs[i, 3],
nquarters,Mcycle,n_extra_R,startquarter,endquarter, EM_comp_fleet,
dat_name,ctl_name,ss_name,
clean = TRUE,plot = FALSE,MSY = FALSE
)
IATTCMSE::BET_MSE(pdir,HS,HCR = HCR,OM = runs[i, 5],itrnum = runs[i, 3],
nquarters,Mcycle,n_extra_R,startquarter,endquarter, EM_comp_fleet,
dat_name,ctl_name,ss_name,
clean = TRUE,plot = FALSE,MSY = FALSE
)
library(IATTCMSE)
library(dplyr)
library(foreach)
library(doParallel)
# Specify path of parent directory
pdir <- "D:/OneDrive - IATTC/IATTC/2025/MSE/Test2/"
# Dimensions
niterations <- 10
nyears <- 21
nquarters <- nyears * 4
Mcycle <- 3
nsteps <- nyears / Mcycle
endquarter <- 200
startquarter <- 17
n_extra_R <- 2 # number of assessment period recruitment in the projection
EM_comp_fleet <- c(4, 23) # fleets with comps in ASPM Rdevs+
dat_name <- "BET-EPO.dat"
ctl_name <- "BET-EPO.ctl"
ss_name <- "ss.exe"
model = c("Fix", "Gro", "Sel", "Mrt")
catchability = c(1, 1.01, 1.02)
steepness = c(1, 0.9, 0.8)
converge <- array(1, dim = c(length(model), length(catchability), length(steepness)))
# converge[1, 3, 3] <- 0
# converge[4, 2, 2:3] <- 0
OM_list <- data.frame(expand.grid(
Model = model,
Catchability = catchability,
Steepness = steepness
))
OM_list$converge <- converge[1:36]
OM_list <- OM_list %>% filter(converge == 1)
OM_name <- paste0(OM_list$Model, "-", OM_list$Catchability, "-", OM_list$Steepness)
OM <- paste0(OM_name, "/")
HCR_name <- "HCR_1"
HCR <- paste0(HCR_name, "/")
# Set the harvest strategy
HSnum <- 1
HS <- paste0("HS", HSnum, "/")
dir.create(paste0(pdir, HS)) # for that harvest strategy
for (OMnum in 1:length(OM)) {
# create a folder for all iterations
unlink(paste0(pdir, HS, HCR, OM[OMnum]), recursive = TRUE)
dir.create(paste0(pdir, HS, HCR, OM[OMnum])) # for that OM
}
Weight_M <- data.frame("Model" = model, "Weight_M" =  rep(1 / length(model), length(model)))
Weight_Q <- data.frame("Catchability" = catchability, "Weight_Q" = rep(1 / length(catchability), length(catchability)))
Weight_S <- data.frame("Steepness" = steepness, "Weight_S" = c(0.46, 0.32, 0.22))
# specify the run list
runs <- data.frame(expand.grid(
Model = model,
Catchability = catchability,
itr = 1:niterations
))
runs$Steepness <- NA
Weight_tot <- left_join(left_join(left_join(OM_list,Weight_M),Weight_Q),Weight_S) %>%
group_by(Model, Catchability) %>%
mutate(Weight_S2 = Weight_S / sum(Weight_S) * niterations)
for (m in 1:length(model)) {
for (q in 1:length(catchability)) {
Weight_1 <- Weight_tot %>% filter(Model == model[m], Catchability == catchability[q], Steepness == 1)
Weight_0.9 <- Weight_tot %>% filter(Model == model[m], Catchability == catchability[q], Steepness == 0.9)
Weight_0.8 <- Weight_tot %>% filter(Model == model[m], Catchability == catchability[q], Steepness == 0.8)
n_1 <- round(sum(Weight_1$Weight_S2, na.rm = TRUE))
n_0.9 <- round(sum(Weight_0.9$Weight_S2, na.rm = TRUE))
runs$Steepness[which(runs$Model==model[m]&runs$Catchability==catchability[q])][1:n_1] <- 1
if(n_1 < niterations) runs$Steepness[which(runs$Model==model[m]&runs$Catchability==catchability[q])][(n_1+1):(n_1+n_0.9)] <- 0.9
if(n_1 + n_0.9 < niterations) runs$Steepness[which(runs$Model==model[m]&runs$Catchability==catchability[q])][(n_1+n_0.9+1):niterations] <- 0.8
}
}
counts <- runs %>% group_by(Model, Catchability, Steepness) %>% summarise(n=n())
runs$OM <- paste0(runs$Model, "-", runs$Catchability, "-", runs$Steepness, "/")
# runs <- runs %>% filter(OM == "Fix-1-1/")
# Calculate the numbers of cores
no_cores = 12 # detectCores() - 2
# Initiate cluster
cl = makeCluster(no_cores)
registerDoParallel(cl)
# *************************************************************************************
# step 1: initialize the OM by copying from the benchmark assessment model
# *************************************************************************************
sdir <- paste0(pdir, HS, HCR)
foreach(i = 1:length(OM_name)) %dopar% {
IATTCMSE::Initialize_OM(pdir, sdir, HS, HCR, OM[i], dat_name, ctl_name, ss_name)
}
sidr
sdir
library(IATTCMSE)
library(dplyr)
library(foreach)
library(doParallel)
# Specify path of parent directory
pdir <- "D:/OneDrive - IATTC/IATTC/2025/MSE/Test2/"
# Specify the path of conditioned initial OM
sdir <- "D:/OneDrive - IATTC/IATTC/2025/Update_Assessment/TRPs/"
# Dimensions
niterations <- 10
nyears <- 21
nquarters <- nyears * 4
Mcycle <- 3
nsteps <- nyears / Mcycle
endquarter <- 200
startquarter <- 17
n_extra_R <- 2 # number of assessment period recruitment in the projection
EM_comp_fleet <- c(4, 23) # fleets with comps in ASPM Rdevs+
dat_name <- "BET-EPO.dat"
ctl_name <- "BET-EPO.ctl"
ss_name <- "ss.exe"
model = c("Fix", "Gro", "Sel", "Mrt")
catchability = c(1, 1.01, 1.02)
steepness = c(1, 0.9, 0.8)
converge <- array(1, dim = c(length(model), length(catchability), length(steepness)))
# converge[1, 3, 3] <- 0
# converge[4, 2, 2:3] <- 0
OM_list <- data.frame(expand.grid(
Model = model,
Catchability = catchability,
Steepness = steepness
))
OM_list$converge <- converge[1:36]
OM_list <- OM_list %>% filter(converge == 1)
OM_name <- paste0(OM_list$Model, "-", OM_list$Catchability, "-", OM_list$Steepness)
OM <- paste0(OM_name, "/")
HCR_name <- "HCR_1"
HCR <- paste0(HCR_name, "/")
# Set the harvest strategy
HSnum <- 1
HS <- paste0("HS", HSnum, "/")
dir.create(paste0(pdir, HS)) # for that harvest strategy
for (OMnum in 1:length(OM)) {
# create a folder for all iterations
unlink(paste0(pdir, HS, HCR, OM[OMnum]), recursive = TRUE)
dir.create(paste0(pdir, HS, HCR, OM[OMnum])) # for that OM
}
Weight_M <- data.frame("Model" = model, "Weight_M" =  rep(1 / length(model), length(model)))
Weight_Q <- data.frame("Catchability" = catchability, "Weight_Q" = rep(1 / length(catchability), length(catchability)))
Weight_S <- data.frame("Steepness" = steepness, "Weight_S" = c(0.46, 0.32, 0.22))
# specify the run list
runs <- data.frame(expand.grid(
Model = model,
Catchability = catchability,
itr = 1:niterations
))
runs$Steepness <- NA
Weight_tot <- left_join(left_join(left_join(OM_list,Weight_M),Weight_Q),Weight_S) %>%
group_by(Model, Catchability) %>%
mutate(Weight_S2 = Weight_S / sum(Weight_S) * niterations)
for (m in 1:length(model)) {
for (q in 1:length(catchability)) {
Weight_1 <- Weight_tot %>% filter(Model == model[m], Catchability == catchability[q], Steepness == 1)
Weight_0.9 <- Weight_tot %>% filter(Model == model[m], Catchability == catchability[q], Steepness == 0.9)
Weight_0.8 <- Weight_tot %>% filter(Model == model[m], Catchability == catchability[q], Steepness == 0.8)
n_1 <- round(sum(Weight_1$Weight_S2, na.rm = TRUE))
n_0.9 <- round(sum(Weight_0.9$Weight_S2, na.rm = TRUE))
runs$Steepness[which(runs$Model==model[m]&runs$Catchability==catchability[q])][1:n_1] <- 1
if(n_1 < niterations) runs$Steepness[which(runs$Model==model[m]&runs$Catchability==catchability[q])][(n_1+1):(n_1+n_0.9)] <- 0.9
if(n_1 + n_0.9 < niterations) runs$Steepness[which(runs$Model==model[m]&runs$Catchability==catchability[q])][(n_1+n_0.9+1):niterations] <- 0.8
}
}
counts <- runs %>% group_by(Model, Catchability, Steepness) %>% summarise(n=n())
runs$OM <- paste0(runs$Model, "-", runs$Catchability, "-", runs$Steepness, "/")
# runs <- runs %>% filter(OM == "Fix-1-1/")
# Calculate the numbers of cores
no_cores = 12 # detectCores() - 2
# Initiate cluster
cl = makeCluster(no_cores)
registerDoParallel(cl)
# *************************************************************************************
# step 1: initialize the OM by copying from the benchmark assessment model
# *************************************************************************************
foreach(i = 1:length(OM_name)) %dopar% {
IATTCMSE::Initialize_OM(pdir, sdir, HS, HCR, OM[i], dat_name, ctl_name, ss_name)
}
library(r4ss)
library(foreach)
library(doParallel)
#Calculate the numbers of cores
no_cores = 12 # detectCores() - 2
#Initiate cluster
cl = makeCluster(no_cores)
registerDoParallel(cl)
Dir <- "D:/OneDrive - IATTC/IATTC/2025/Update_Assessment/TRPs/"
NewDir <- "D:/OneDrive - IATTC/IATTC/2025/Update_Assessment/F40/"
model <- c("Fix", "Gro", "Sel", "Mrt")
catchability <- c(1, 1.01, 1.02)
steepness <- c(1, 0.9, 0.8)
converge <- array(1, dim = c(length(model), length(catchability), length(steepness)))
# converge[1,3,3] <- 0
# converge[4,2,2:3] <- 0
runs <- data.frame(expand.grid(
m = 1:length(model),
q = 1:length(catchability),
s = 1:length(steepness)
))
Run_SS = function (m, q, s) {
if (converge[m, q, s]) {
# original path
Path <- paste0(Dir, model[m], "-", catchability[q], "-", steepness[s])
# new path
Path_new <- paste0(NewDir, model[m], "-", catchability[q], "-", steepness[s])
# base path
Path_base <- NewDir
dir.create(Path_new)
# copy SS files
files = c(
paste0(Path, "/go.bat"),
paste0(Path, "/go_nohess.bat"),
paste0(Path_base, "/starter.ss"),
paste0(Path_base, "/forecast.ss"),
paste0(Path, "/BET-EPO.ctl"),
paste0(Path, "/BET-EPO.dat"),
paste0(Path_base, "/ss.exe"),
paste0(Path, "/ss3.par")
)
file.copy(from = files,
to = Path_new,
overwrite = TRUE)
setwd(Path_new)
print(Path_new)
# run the model
command <- paste("cd", Path_new, "& go_nohess.bat", sep = " ")
ss <- shell(cmd = command, intern = T)
}
}
foreach(i = 1:nrow(runs)) %dopar% { Run_SS(runs[i,1], runs[i,2], runs[i,3]) }
stopCluster(cl)
library(r4ss)
library(foreach)
library(doParallel)
#Calculate the numbers of cores
no_cores = 12 # detectCores() - 2
#Initiate cluster
cl = makeCluster(no_cores)
registerDoParallel(cl)
Dir <- "D:/OneDrive - IATTC/IATTC/2025/Update_Assessment/TRPs/"
NewDir <- "D:/OneDrive - IATTC/IATTC/2025/Update_Assessment/F40/"
model <- c("Fix", "Gro", "Sel", "Mrt")
catchability <- c(1, 1.01, 1.02)
steepness <- c(1, 0.9, 0.8)
converge <- array(1, dim = c(length(model), length(catchability), length(steepness)))
# converge[1,3,3] <- 0
# converge[4,2,2:3] <- 0
runs <- data.frame(expand.grid(
m = 1:length(model),
q = 1:length(catchability),
s = 1:length(steepness)
))
Run_SS = function (m, q, s) {
if (converge[m, q, s]) {
# original path
Path <- paste0(Dir, model[m], "-", catchability[q], "-", steepness[s])
# new path
Path_new <- paste0(NewDir, model[m], "-", catchability[q], "-", steepness[s])
# base path
Path_base <- NewDir
dir.create(Path_new)
# copy SS files
files = c(
paste0(Path, "/go.bat"),
paste0(Path, "/go_nohess.bat"),
paste0(Path_base, "/starter.ss"),
paste0(Path_base, "/forecast.ss"),
paste0(Path, "/BET-EPO.ctl"),
paste0(Path, "/BET-EPO.dat"),
paste0(Path_base, "/ss.exe"),
paste0(Path, "/ss3.par")
)
file.copy(from = files,
to = Path_new,
overwrite = TRUE)
setwd(Path_new)
print(Path_new)
# run the model
command <- paste("cd", Path_new, "& go_nohess.bat", sep = " ")
ss <- shell(cmd = command, intern = T)
}
}
foreach(i = 1:nrow(runs)) %dopar% { Run_SS(runs[i,1], runs[i,2], runs[i,3]) }
stopCluster(cl)
library(IATTCassessment)
Dir <- "D:/OneDrive - IATTC/IATTC/2025/Update_Assessment/F40/"
model <- c("Fix", "Gro", "Sel", "Mrt")
catchability <- c(1, 1.01, 1.02)
steepness <- c(1, 0.9, 0.8)
converge <- array(1, dim = c(length(model), length(catchability), length(steepness)))
# converge[1,3,3] <- 0
# converge[4,2,2:3] <- 0
for (m in 1:length(model)) {
for (q in 1:length(catchability)) {
for (s in 1:length(steepness)) {
if(converge[m,q,s]) {
Path <- paste0(Dir, model[m], "-", catchability[q], "-", steepness[s], "/")
# FlimitPath <- paste0(FlimitDir, model[m], "-", catchability[q], "-", steepness[s], "/")
# dMSYPath <- paste0(dMSYDir, model[m], "-", catchability[q], "-", steepness[s], "/")
print(Path)
# 4/22/2025 add F/FMSY for the 2025 yellowfin assessment; code copied from makeMagagTable.new
ForeRepName <- paste(Path, "Forecast-report.SSO", sep = "")
# Get management report
ForeRepStart <- grep("Management_report", readLines(ForeRepName))
ForeRepEnd <- grep("THIS FORECAST IS FOR PURPOSES", readLines(ForeRepName))[1]
# ForeDat <- read.table(file=ForeRepName,col.names=c(seq(1,10,by=1)),fill=T,quote='',colClasses='character',
# nrows=45, skip = ForeRepStart-1)
ForeDat <- read.table(file = ForeRepName, col.names = c(seq(1, 10, by = 1)), fill = T, quote = "", colClasses = "character",
nrows = ForeRepEnd - ForeRepStart, skip = ForeRepStart - 1)
ForeDat <- as.data.frame(ForeDat)
FvectorRepStart <- grep("Seasonal_apicalF=Fmult", readLines(ForeRepName))
Fvector <- read.table(file = ForeRepName, nrows = 1, skip = FvectorRepStart[1] + 1)
Fvector <- Fvector[3:length(Fvector)]
FmultScale <- sum(Fvector)
# # Fmultiplier
Fmult <- as.numeric(ForeDat[ForeDat[, 1] == c("Fmult"), 2])[3]
FF30 <- FmultScale/Fmult
#dSBR
# read EM output file
myreplist <- r4ss::SS_output(Path, covar = FALSE, verbose = FALSE, printstats = FALSE)
Dynamic_Bzero <- myreplist$Dynamic_Bzero
SBR_d <- Dynamic_Bzero$SSB[nrow(Dynamic_Bzero)] / Dynamic_Bzero$SSB_nofishing[nrow(Dynamic_Bzero)]
if(m+s+q==3) {
Fmult_df <- data.frame("F30"=Fmult, "FF30"=FF30, "dSBR"=SBR_d, "model"=model[m], "catchability"=catchability[q], "steepness"=steepness[s])
}
else {
Fmult_df <- rbind(Fmult_df,
data.frame("F30"=Fmult, "FF30"=FF30, "dSBR"=SBR_d, "model"=model[m], "catchability"=catchability[q], "steepness"=steepness[s]))
}
}
}
}
}
write.csv(Fmult_df,file=paste0(Dir,"Fmult-30.csv"),row.names = FALSE)
warnings()
Path <- "D:/OneDrive - IATTC/IATTC/2025/MSE/Test2/HS1/HCR_1/EM/"
print(Path)
# 4/22/2025 add F/FMSY for the 2025 yellowfin assessment; code copied from makeMagagTable.new
ForeRepName <- paste(Path, "Forecast-report.SSO", sep = "")
# Get management report
ForeRepStart <- grep("Management_report", readLines(ForeRepName))
ForeRepEnd <- grep("THIS FORECAST IS FOR PURPOSES", readLines(ForeRepName))[1]
# ForeDat <- read.table(file=ForeRepName,col.names=c(seq(1,10,by=1)),fill=T,quote='',colClasses='character',
# nrows=45, skip = ForeRepStart-1)
ForeDat <- read.table(file = ForeRepName, col.names = c(seq(1, 10, by = 1)), fill = T, quote = "", colClasses = "character",
nrows = ForeRepEnd - ForeRepStart, skip = ForeRepStart - 1)
ForeDat <- as.data.frame(ForeDat)
FvectorRepStart <- grep("Seasonal_apicalF=Fmult", readLines(ForeRepName))
Fvector <- read.table(file = ForeRepName, nrows = 1, skip = FvectorRepStart[1] + 1)
Fvector <- Fvector[3:length(Fvector)]
FmultScale <- sum(Fvector)
# # Fmultiplier
Fmult <- as.numeric(ForeDat[ForeDat[, 1] == c("Fmult"), 2])[3]
FF30 <- FmultScale/Fmult
#dSBR
# read EM output file
myreplist <- r4ss::SS_output(Path, covar = FALSE, verbose = FALSE, printstats = FALSE)
Dynamic_Bzero <- myreplist$Dynamic_Bzero
SBR_d <- Dynamic_Bzero$SSB[nrow(Dynamic_Bzero)] / Dynamic_Bzero$SSB_nofishing[nrow(Dynamic_Bzero)]
Fmult_df <- data.frame("F30"=Fmult, "FF30"=FF30, "dSBR"=SBR_d, "model"=model[m], "catchability"=catchability[q], "steepness"=steepness[s])
View(Fmult_df)
Fmult_df
library(IATTCMSE)
library(dplyr)
library(foreach)
library(doParallel)
# Specify path of parent directory
pdir <- "D:/OneDrive - IATTC/IATTC/2025/MSE/Test2/"
# Specify the path of conditioned initial OM
sdir <- "D:/OneDrive - IATTC/IATTC/2025/Update_Assessment/F40/"
# Dimensions
niterations <- 10
nyears <- 21
nquarters <- nyears * 4
Mcycle <- 3
nsteps <- nyears / Mcycle
endquarter <- 200
startquarter <- 17
n_extra_R <- 2 # number of assessment period recruitment in the projection
EM_comp_fleet <- c(4, 23) # fleets with comps in ASPM Rdevs+
dat_name <- "BET-EPO.dat"
ctl_name <- "BET-EPO.ctl"
ss_name <- "ss.exe"
model = c("Fix", "Gro", "Sel", "Mrt")
catchability = c(1, 1.01, 1.02)
steepness = c(1, 0.9, 0.8)
converge <- array(1, dim = c(length(model), length(catchability), length(steepness)))
# converge[1, 3, 3] <- 0
# converge[4, 2, 2:3] <- 0
OM_list <- data.frame(expand.grid(
Model = model,
Catchability = catchability,
Steepness = steepness
))
OM_list$converge <- converge[1:36]
OM_list <- OM_list %>% filter(converge == 1)
OM_name <- paste0(OM_list$Model, "-", OM_list$Catchability, "-", OM_list$Steepness)
OM <- paste0(OM_name, "/")
HCR_name <- "HCR_1"
HCR <- paste0(HCR_name, "/")
# Set the harvest strategy
HSnum <- 1
HS <- paste0("HS", HSnum, "/")
dir.create(paste0(pdir, HS)) # for that harvest strategy
for (OMnum in 1:length(OM)) {
# create a folder for all iterations
unlink(paste0(pdir, HS, HCR, OM[OMnum]), recursive = TRUE)
dir.create(paste0(pdir, HS, HCR, OM[OMnum])) # for that OM
}
Weight_M <- data.frame("Model" = model, "Weight_M" =  rep(1 / length(model), length(model)))
Weight_Q <- data.frame("Catchability" = catchability, "Weight_Q" = rep(1 / length(catchability), length(catchability)))
Weight_S <- data.frame("Steepness" = steepness, "Weight_S" = c(0.46, 0.32, 0.22))
# specify the run list
runs <- data.frame(expand.grid(
Model = model,
Catchability = catchability,
itr = 1:niterations
))
runs$Steepness <- NA
Weight_tot <- left_join(left_join(left_join(OM_list,Weight_M),Weight_Q),Weight_S) %>%
group_by(Model, Catchability) %>%
mutate(Weight_S2 = Weight_S / sum(Weight_S) * niterations)
for (m in 1:length(model)) {
for (q in 1:length(catchability)) {
Weight_1 <- Weight_tot %>% filter(Model == model[m], Catchability == catchability[q], Steepness == 1)
Weight_0.9 <- Weight_tot %>% filter(Model == model[m], Catchability == catchability[q], Steepness == 0.9)
Weight_0.8 <- Weight_tot %>% filter(Model == model[m], Catchability == catchability[q], Steepness == 0.8)
n_1 <- round(sum(Weight_1$Weight_S2, na.rm = TRUE))
n_0.9 <- round(sum(Weight_0.9$Weight_S2, na.rm = TRUE))
runs$Steepness[which(runs$Model==model[m]&runs$Catchability==catchability[q])][1:n_1] <- 1
if(n_1 < niterations) runs$Steepness[which(runs$Model==model[m]&runs$Catchability==catchability[q])][(n_1+1):(n_1+n_0.9)] <- 0.9
if(n_1 + n_0.9 < niterations) runs$Steepness[which(runs$Model==model[m]&runs$Catchability==catchability[q])][(n_1+n_0.9+1):niterations] <- 0.8
}
}
counts <- runs %>% group_by(Model, Catchability, Steepness) %>% summarise(n=n())
runs$OM <- paste0(runs$Model, "-", runs$Catchability, "-", runs$Steepness, "/")
# runs <- runs %>% filter(OM == "Fix-1-1/")
# Calculate the numbers of cores
no_cores = 12 # detectCores() - 2
# Initiate cluster
cl = makeCluster(no_cores)
registerDoParallel(cl)
# *************************************************************************************
# step 1: initialize the OM by copying from the benchmark assessment model
# *************************************************************************************
foreach(i = 1:length(OM_name)) %dopar% {
IATTCMSE::Initialize_OM(pdir, sdir, HS, HCR, OM[i], dat_name, ctl_name, ss_name)
}
# i = 25; OM = runs[i, 5]; itrnum = runs[i, 3];
# clean = TRUE; plot = FALSE; MSY = FALSE
# IATTCMSE::BET_MSE(pdir,sdir,HS,HCR = HCR,OM = runs[i, 5],itrnum = runs[i, 3],
#   nquarters,Mcycle,n_extra_R,startquarter,endquarter, EM_comp_fleet,
#   dat_name,ctl_name,ss_name,
#   clean = TRUE,plot = FALSE,MSY = FALSE
# )
# run the MSE
foreach(i = 1:nrow(runs)) %dopar% {
IATTCMSE::BET_MSE(
pdir,
HS,
HCR,
OM = runs[i, 5],
itrnum = runs[i, 3],
nquarters,
Mcycle,
n_extra_R,
startquarter,
endquarter,
EM_comp_fleet,
dat_name,
ctl_name,
ss_name,
clean = TRUE,
plot = FALSE,
MSY = FALSE
)
}
devtools::document()
# Calculate the numbers of cores
no_cores = 12 # detectCores() - 2
# Initiate cluster
cl = makeCluster(no_cores)
